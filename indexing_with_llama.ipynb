{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'ServiceContext' from 'llama_index' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdotenv\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dotenv\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpath\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      7\u001b[0m     ServiceContext,\n\u001b[1;32m      8\u001b[0m     SimpleDirectoryReader,\n\u001b[1;32m      9\u001b[0m     StorageContext,\n\u001b[1;32m     10\u001b[0m     VectorStoreIndex,\n\u001b[1;32m     11\u001b[0m     load_index_from_storage,\n\u001b[1;32m     12\u001b[0m )\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext_splitter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceSplitterpip \n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# openai_api_key = os.getenv(\"OPENAI_API_KEY\")\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# openai.api_key = openai_api_key\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'ServiceContext' from 'llama_index' (unknown location)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "import os.path\n",
    "\n",
    "from llama_index import (\n",
    "    ServiceContext,\n",
    "    SimpleDirectoryReader,\n",
    "    StorageContext,\n",
    "    VectorStoreIndex,\n",
    "    load_index_from_storage,\n",
    ")\n",
    "from llama_index.text_splitter import SentenceSplitterpip\n",
    "\n",
    "\n",
    "# openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "# openai.api_key = openai_api_key\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smaller chunks might get more precise info while larger chunks get more context\n",
    "# defaults are chunk_size=1024 and chunk_overlap=20\n",
    "text_splitter = SentenceSplitter(chunk_size=1024, chunk_overlap=20)\n",
    "\n",
    "# ServiceContext provides various customization options\n",
    "service_context = ServiceContext.from_defaults(text_splitter=text_splitter)\n",
    "\n",
    "# function to get the filename later used as metadata\n",
    "filename_fn = lambda filename: {\"file_name\": filename}\n",
    "\n",
    "# check if storage already exists\n",
    "if not os.path.exists(\"./storage\"):\n",
    "    # load the documents and set the filename as metadata\n",
    "    documents = SimpleDirectoryReader(\n",
    "        \"data\",\n",
    "        file_metadata=filename_fn,\n",
    "        filename_as_id=True # path to doc as doc_id\n",
    "    ).load_data()\n",
    "\n",
    "    # creates the index, service context provides customizations for index building\n",
    "    index = VectorStoreIndex.from_documents(documents, service_context=service_context)\n",
    "\n",
    "    # store it for later\n",
    "    index.storage_context.persist()\n",
    "else:\n",
    "    # load the existing index\n",
    "    storage_context = StorageContext.from_defaults(persist_dir=\"./storage\")\n",
    "    index = load_index_from_storage(storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "# You can set the level to DEBUG for verbose output, or use level=logging.INFO for less.\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Israel is breaking international law by building settlements in the West Bank, including in East Jerusalem. This violates the Hague Regulations, which prohibit the confiscation of private property, and the Fourth Geneva Convention, which prohibits the destruction of private or state property except where necessary for military operations. The settlements also involve the unlawful appropriation of property by an occupying power, which is considered \"pillage\" and is prohibited by international law. Additionally, transferring the occupying power's civilians into the occupied territory is prohibited. These actions constitute war crimes under the Rome Statute of the International Criminal Court. The expansion of settlements has also resulted in the reduction of land available to Palestinians for herding and agriculture, leading to increased dependency on humanitarian assistance. Settler violence and the destruction of Palestinian-owned crops and olive trees have further harmed the livelihoods of farmers. The international community, including the European Union and the United Nations, has condemned Israeli settlements as illegal under international law.\n"
     ]
    }
   ],
   "source": [
    "# more context with similarity_top_k\n",
    "query_engine = index.as_query_engine(\n",
    "    similarity_top_k=5,\n",
    "    response_mode=\"tree_summarize\",\n",
    "    streaming=True,\n",
    "    )\n",
    "\n",
    "response = query_engine.query(\"How is Israel breaking international law?\")\n",
    "# chat bot instead of q&a\n",
    "# response = query_engine.chat(\"How is Israel breaking international law?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File path where you want to save the text file\n",
    "file_path = \"israel int law violations.txt\"\n",
    "\n",
    "# Open the file in write mode ('w')\n",
    "with open(file_path, 'w') as file:\n",
    "    # Write the string to the file\n",
    "    file.write(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Texts with regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    # Remove text inside square brackets (footnotes, references, etc.)\n",
    "    text = re.sub(r'\\[.*?\\]', '', text)\n",
    "\n",
    "    # Replace single line breaks (\\n) that are not followed by another line break with a space\n",
    "    text = re.sub(r'\\n(?!\\n)', ' ', text)\n",
    "\n",
    "    # Remove lines matching the specified patterns\n",
    "    # text = re.sub(r'^This content downloaded from .*$', '', text, flags=re.MULTILINE)\n",
    "    # text = re.sub(r'^All use subject to .*$', '', text, flags=re.MULTILINE)\n",
    "\n",
    "    return text\n",
    "\n",
    "# Directory path containing files to be cleaned\n",
    "directory_path = './documents/'\n",
    "\n",
    "# Iterate through all files in the directory\n",
    "for filename in os.listdir(directory_path):\n",
    "    if filename.endswith('.txt'):  # Process only .txt files (change as needed)\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "\n",
    "        # Read text from the file\n",
    "        with open(file_path, 'r') as file:\n",
    "            text_from_file = file.read()\n",
    "\n",
    "        # Clean the text using the function\n",
    "        cleaned_text = clean_text(text_from_file)\n",
    "\n",
    "        # Overwrite the original file with the cleaned content\n",
    "        with open(file_path, 'w') as file:\n",
    "            file.write(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Metadata from texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import SimpleDirectoryReader\n",
    "\n",
    "def extract_metadata(file_path: str):\n",
    "    \"\"\"\n",
    "    This function should extract the metadata from the content of the file.\n",
    "    For the sake of this example, let's assume that the metadata is always at the beginning of the file in the format 'author: John Doe\\ndate: 2022-01-01\\nsource: Newspaper\\nweblink: www.newspaper.com\\nBegin!\\n'.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    metadata = {}\n",
    "    for line in lines:\n",
    "        if line.strip() == 'Begin!':\n",
    "            break\n",
    "        key, value = line.strip().split(': ')\n",
    "        metadata[key] = value\n",
    "\n",
    "    return metadata\n",
    "\n",
    "# Create the SimpleDirectoryReader instance with the metadata extraction function\n",
    "reader = SimpleDirectoryReader(\"./documents\", file_metadata=extract_metadata)\n",
    "\n",
    "# Load the documents\n",
    "documents = reader.load_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
